# MIPT DLS

Репозиторий содержит выполненные домашние задания по первой части курса **Deep Learning** от [Школы глубокого обучения](https://www.dlschool.org/) МФТИ.
Работы выполнены мной при прохождении осеннего запуска (2023) курса. [Stepik](https://stepik.org/course/82176).

## Список работ:

1. **Основы машинного обучения и линейные модели**
    
    Обучен простейший классификатор (метод K Nearest Neighbors) на табличных данных c применением Grid Search с помощью средств библиотек pandas и sklearn.
    
    10/10
    
    Реализованы функция градиентного спуска для конкретной заданной функции f, генератор батчей, класс для логистической регрессии с регуляризацией (l1 и l2). Класс протестирован обучением на сгенерированных данных и обучением на MNIST с применением кросс-валидации.
    
    12/12
   
4. **Введение в нейронные сети**

    Реализованы класс для логистической регрессии и цикл обучения на PyTorch. Сравнены несколько функций активации обучением простейшей трёхслойной нейронной сети на MNIST. Сравнены вручную заданные ядра свёрток. Обучена LeNet на MNIST.

    14/14

5. **Работа с CV**

   В этом домашнем задании вам предстоит заполнить ноутбук по ссылке. Ваша главная цель -- это заполнить пропуски в клетках с кодом. Обратите внимание, что это задание также подразумевает peer review. Для упрощения процедуры peer review, мы ввели контрольные вопросы, на которые вам нужно ответить после выполнения каждого смыслового куска заполненного вами кода.  
   14/14

   Kaggle-соревнование. Сегодня вам предстоить помочь телекомпании FOX в обработке их контента. Как вы знаете, сериал "Симпсоны" идет на телеэкранах более 25 лет, и за это время скопилось очень много видеоматериала. Персоонажи менялись вместе с изменяющимися графическими технологиями, и Гомер Симпсон-2018 не очень похож на Гомера Симпсона-1989. В этом задании вам необходимо классифицировать персонажей, проживающих в Спрингфилде.  
   12/15

   Решение задачи сегментации медицинских снимков. Реализация архитектур SegNet, UNet и различных Loss функций.  
   20/20  
